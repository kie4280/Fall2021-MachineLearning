{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Name: 張宸愷\n",
    "> ID: 0710018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#-------------------------#\n",
    "# Some parameters\n",
    "do_PCA = True\n",
    "bin_5_classf = 1\n",
    "PCA_dim = 2\n",
    "\n",
    "#-------------------------#\n",
    "\n",
    "df = pd.read_csv(\"data/student-mat.csv\", sep=\";\")  # read csv. I used the mathematics dataset\n",
    "\n",
    "cats = df.select_dtypes(include=[object])  # select categorical features\n",
    "num = df.select_dtypes(include=[int])  # select numerical features\n",
    "cats = pd.get_dummies(cats)  # onehot encode\n",
    "\n",
    "# combine numerical and categorical data\n",
    "data_orig = pd.concat([cats, num], axis=1)\n",
    "\n",
    "if bin_5_classf == 0:\n",
    "\n",
    "    classes = [\"pass\", \"fail\"]\n",
    "    data_orig['G3'] = data_orig['G3'].apply(\n",
    "        lambda x: 0 if x > 10 else 1)\n",
    "\n",
    "elif bin_5_classf == 1:\n",
    "    classes = [\"I\", \"II\", \"III\", \"IV\", \"V\"]\n",
    "\n",
    "    def conv(x):\n",
    "        if x >= 16:\n",
    "            return 0\n",
    "        if x >= 14:\n",
    "            return 1\n",
    "        if x >= 12:\n",
    "            return 2\n",
    "        if x >= 10:\n",
    "            return 3\n",
    "\n",
    "        return 4\n",
    "\n",
    "    data_orig['G3'] = data_orig['G3'].apply(conv)\n",
    "\n",
    "\n",
    "\n",
    "data = data_orig.to_numpy()  # get the binary classification data\n",
    "# np.random.shuffle(data)\n",
    "clss = len(classes)\n",
    "feature_num = data.shape[1]-1\n",
    "# print(data_orig.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report classification\n",
      "     precision    recall  accuracy\n",
      "I     0.753429  0.766667  0.615159\n",
      "II    0.541999  0.597222  0.615159\n",
      "III   0.425926  0.447012  0.615159\n",
      "IV    0.525694  0.519319  0.615159\n",
      "V     0.785815  0.742848  0.615159\n",
      "\n",
      "confusion matrix\n",
      "             pred I    pred II  pred III    pred IV     pred V\n",
      "true I    10.333333   2.666667  0.333333   0.000000   0.000000\n",
      "true II    2.666667  12.000000  5.000000   0.333333   0.000000\n",
      "true III   0.333333   5.333333  9.333333   5.333333   0.333333\n",
      "true IV    0.000000   1.666667  6.000000  17.666667   9.000000\n",
      "true V     0.000000   0.000000  1.000000  10.666667  31.666667\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "\n",
    "def r2np(r: dict):\n",
    "    nn = np.ndarray((len(classes), 3))\n",
    "    for c in range(len(classes)):\n",
    "        a = str(c)\n",
    "        nn[c] = [r[a][\"precision\"], r[a][\"recall\"], r[\"accuracy\"]]\n",
    "\n",
    "    # return [precision, recall, accuracy]\n",
    "    return nn\n",
    "\n",
    "\n",
    "def decision_t(X_train:np.ndarray, y_train: np.ndarray, X_test:np.ndarray, y_test: np.ndarray):\n",
    "    T_cls = tree.DecisionTreeClassifier()\n",
    "    T_cls.fit(X_train, y_train)\n",
    "    y_pred = T_cls.predict(X_test)\n",
    "    r = classification_report(y_test, y_pred, output_dict=True)\n",
    "    c = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return r, c, T_cls\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "T_cls = None\n",
    "rs = np.zeros((len(classes), 3))\n",
    "cs = np.zeros((clss, clss))\n",
    "for train_index, test_index in kfold.split(data):\n",
    "    train, test = data[train_index], data[test_index]\n",
    "    X_train, y_train, X_test, y_test = train[:,0:-1], train[:,-1], test[:,0:-1], test[:,-1]\n",
    "    pca = PCA(n_components=PCA_dim)\n",
    "    if do_PCA:\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "    r, confm, T_cls = decision_t(X_train, y_train, X_test, y_test)\n",
    "    rs += r2np(r)\n",
    "    cs += confm\n",
    "# get average\n",
    "rs = rs/3\n",
    "cs = cs/3\n",
    "\n",
    "\n",
    "# show data\n",
    "rs = pd.DataFrame(rs, index=classes, columns=[\n",
    "                  'precision', 'recall', 'accuracy'])\n",
    "print(\"report classification\")\n",
    "print(rs)\n",
    "cs = pd.DataFrame(cs, index=[\"true \" + x for x in classes],\n",
    "                  columns=[\"pred \" + x for x in classes])\n",
    "print(\"\")\n",
    "print(\"confusion matrix\")\n",
    "print(cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report classification\n",
      "     precision    recall  accuracy\n",
      "I     0.770940  0.729167  0.663351\n",
      "II    0.596686  0.622807  0.663351\n",
      "III   0.504926  0.514245  0.663351\n",
      "IV    0.578078  0.605470  0.663351\n",
      "V     0.817413  0.786905  0.663351\n",
      "\n",
      "confusion matrix\n",
      "            pred I    pred II   pred III    pred IV     pred V\n",
      "true I    9.666667   3.333333   0.333333   0.000000   0.000000\n",
      "true II   3.000000  12.333333   4.000000   0.666667   0.000000\n",
      "true III  0.000000   4.333333  11.000000   5.000000   0.333333\n",
      "true IV   0.000000   0.666667   5.666667  20.333333   7.666667\n",
      "true V    0.000000   0.000000   0.000000   9.333333  34.000000\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#-------------------------#\n",
    "# some parameters\n",
    "num_trees = 50\n",
    "\n",
    "\n",
    "#-------------------------#\n",
    "\n",
    "R_cls = None\n",
    "\n",
    "rs = np.zeros((clss, 3))\n",
    "cs = np.zeros((clss, clss))\n",
    "\n",
    "def random_f(X_train:np.ndarray, y_train: np.ndarray, X_test:np.ndarray, y_test: np.ndarray):\n",
    "    R_cls = RandomForestClassifier(num_trees)    \n",
    "    R_cls.fit(X_train, y_train)\n",
    "    y_pred = R_cls.predict(X_test)\n",
    "    r = classification_report(y_test, y_pred, output_dict=True)\n",
    "    c = confusion_matrix(y_test, y_pred)\n",
    "    return r, c, None\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "R_cls = None\n",
    "rs = np.zeros((len(classes), 3))\n",
    "cs = np.zeros((clss, clss))\n",
    "for train_index, test_index in kfold.split(data):\n",
    "    train, test = data[train_index], data[test_index]\n",
    "    X_train, y_train, X_test, y_test = train[:,0:-1], train[:,-1], test[:,0:-1], test[:,-1]\n",
    "    pca = PCA(n_components=PCA_dim)\n",
    "    if do_PCA:\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "    r, confm, R_cls = random_f(X_train, y_train, X_test, y_test)\n",
    "    rs += r2np(r)\n",
    "    cs += confm\n",
    "rs = rs / 3\n",
    "cs = cs / 3\n",
    "\n",
    "\n",
    "# show data\n",
    "rs = pd.DataFrame(rs, index=classes, columns=[\n",
    "                  'precision', 'recall', 'accuracy'])\n",
    "print(\"report classification\")\n",
    "print(rs)\n",
    "cs = pd.DataFrame(cs, index=[\"true \" + x for x in classes],\n",
    "                  columns=[\"pred \" + x for x in classes])\n",
    "print(\"\")\n",
    "print(\"confusion matrix\")\n",
    "print(cs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report classification\n",
      "     precision    recall  accuracy\n",
      "I     0.835017  0.614286  0.627882\n",
      "II    0.538604  0.644276  0.627882\n",
      "III   0.404101  0.404539  0.627882\n",
      "IV    0.565876  0.518492  0.627882\n",
      "V     0.819258  0.823954  0.627882\n",
      "\n",
      "confusion matrix\n",
      "            pred I    pred II  pred III    pred IV     pred V\n",
      "true I    8.000000   4.666667  0.666667   0.000000   0.000000\n",
      "true II   1.666667  13.000000  4.666667   0.666667   0.000000\n",
      "true III  0.000000   5.333333  8.333333   6.666667   0.333333\n",
      "true IV   0.000000   2.666667  6.333333  17.666667   7.666667\n",
      "true V    0.000000   0.000000  0.666667   7.000000  35.666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#-----------------------#\n",
    "# some parameters\n",
    "K_n = 3\n",
    "\n",
    "#-----------------------#\n",
    "\n",
    "\n",
    "def knn_r(X_train:np.ndarray, y_train: np.ndarray, X_test:np.ndarray, y_test: np.ndarray):\n",
    "    knn = KNeighborsClassifier(n_neighbors=K_n)   \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    r = classification_report(y_test, y_pred, output_dict=True)\n",
    "    c = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return r, c, knn\n",
    "    \n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "knn = None\n",
    "rs = np.zeros((len(classes), 3))\n",
    "cs = np.zeros((clss, clss))\n",
    "for train_index, test_index in kfold.split(data):\n",
    "    train, test = data[train_index], data[test_index]\n",
    "    X_train, y_train, X_test, y_test = train[:,0:-1], train[:,-1], test[:,0:-1], test[:,-1]\n",
    "    pca = PCA(n_components=PCA_dim)\n",
    "    if do_PCA:\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "    r, confm, knn = knn_r(X_train, y_train, X_test, y_test)\n",
    "    rs += r2np(r)\n",
    "    cs += confm\n",
    "rs = rs / 3\n",
    "cs = cs / 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# show data\n",
    "rs = pd.DataFrame(rs, index=classes, columns=[\n",
    "                  'precision', 'recall', 'accuracy'])\n",
    "print(\"report classification\")\n",
    "print(rs)\n",
    "cs = pd.DataFrame(cs, index=[\"true \" + x for x in classes],\n",
    "                  columns=[\"pred \" + x for x in classes])\n",
    "print(\"\")\n",
    "print(\"confusion matrix\")\n",
    "print(cs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qestions\n",
    "\n",
    "## Q1 Decision Tree\n",
    "> Show the prediction and reasoning of one arbitrary sample in the testing set. - 10%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(25, 20), dpi=100)\n",
    "_ = tree.plot_tree(T_cls, feature_names=data_orig.columns,\n",
    "                      class_names=classes,\n",
    "                       filled=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39ee8b2532ba0d367d8a804459f87d5f1b7a64bdde2dae632ea701e04e13d188"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
